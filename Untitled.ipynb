{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0bfa19d-97ed-4d37-985b-02211495cafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in training set:\n",
      "Sleep Disorder\n",
      "2    0.588629\n",
      "1    0.207358\n",
      "0    0.204013\n",
      "Name: proportion, dtype: float64\n",
      "Training LogisticRegression...\n",
      "LogisticRegression - Best Params: {'C': 10}\n",
      "LogisticRegression - Accuracy: 0.9066666666666666\n",
      "LogisticRegression - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.82        16\n",
      "           1       0.92      0.75      0.83        16\n",
      "           2       0.95      0.98      0.97        43\n",
      "\n",
      "    accuracy                           0.91        75\n",
      "   macro avg       0.89      0.87      0.87        75\n",
      "weighted avg       0.91      0.91      0.91        75\n",
      "\n",
      "\n",
      "Training RandomForestClassifier...\n",
      "RandomForestClassifier - Best Params: {'max_depth': None, 'n_estimators': 100}\n",
      "RandomForestClassifier - Accuracy: 0.88\n",
      "RandomForestClassifier - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.81      0.76        16\n",
      "           1       0.85      0.69      0.76        16\n",
      "           2       0.95      0.98      0.97        43\n",
      "\n",
      "    accuracy                           0.88        75\n",
      "   macro avg       0.84      0.83      0.83        75\n",
      "weighted avg       0.88      0.88      0.88        75\n",
      "\n",
      "\n",
      "Training SVC...\n",
      "SVC - Best Params: {'C': 1, 'kernel': 'linear'}\n",
      "SVC - Accuracy: 0.9066666666666666\n",
      "SVC - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.82        16\n",
      "           1       0.92      0.75      0.83        16\n",
      "           2       0.95      0.98      0.97        43\n",
      "\n",
      "    accuracy                           0.91        75\n",
      "   macro avg       0.89      0.87      0.87        75\n",
      "weighted avg       0.91      0.91      0.91        75\n",
      "\n",
      "\n",
      "Training DecisionTreeClassifier...\n",
      "DecisionTreeClassifier - Best Params: {'max_depth': None, 'min_samples_split': 10}\n",
      "DecisionTreeClassifier - Accuracy: 0.8933333333333333\n",
      "DecisionTreeClassifier - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.88      0.80        16\n",
      "           1       0.92      0.69      0.79        16\n",
      "           2       0.95      0.98      0.97        43\n",
      "\n",
      "    accuracy                           0.89        75\n",
      "   macro avg       0.87      0.85      0.85        75\n",
      "weighted avg       0.90      0.89      0.89        75\n",
      "\n",
      "\n",
      "Training KNeighborsClassifier...\n",
      "KNeighborsClassifier - Best Params: {'n_neighbors': 5, 'weights': 'uniform'}\n",
      "KNeighborsClassifier - Accuracy: 0.9066666666666666\n",
      "KNeighborsClassifier - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81        16\n",
      "           1       0.87      0.81      0.84        16\n",
      "           2       0.95      0.98      0.97        43\n",
      "\n",
      "    accuracy                           0.91        75\n",
      "   macro avg       0.88      0.87      0.87        75\n",
      "weighted avg       0.91      0.91      0.91        75\n",
      "\n",
      "\n",
      "Training GradientBoostingClassifier...\n",
      "GradientBoostingClassifier - Best Params: {'learning_rate': 0.01, 'n_estimators': 200}\n",
      "GradientBoostingClassifier - Accuracy: 0.88\n",
      "GradientBoostingClassifier - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.81      0.76        16\n",
      "           1       0.85      0.69      0.76        16\n",
      "           2       0.95      0.98      0.97        43\n",
      "\n",
      "    accuracy                           0.88        75\n",
      "   macro avg       0.84      0.83      0.83        75\n",
      "weighted avg       0.88      0.88      0.88        75\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Sleep_health_and_lifestyle_dataset.csv'\n",
    "dataset = pd.read_csv(file_path)\n",
    "dataset['Sleep Disorder'] = dataset['Sleep Disorder'].fillna('No Disorder')\n",
    "# Encode categorical variables\n",
    "categorical_columns = ['Gender', 'Occupation', 'BMI Category', 'Blood Pressure', 'Sleep Disorder']\n",
    "encoders = {col: LabelEncoder() for col in categorical_columns}\n",
    "for col in categorical_columns:\n",
    "    dataset[col] = encoders[col].fit_transform(dataset[col])\n",
    "\n",
    "# Separate features and target\n",
    "X = dataset.drop(columns=['Person ID', 'Sleep Disorder'])  # Drop ID and target column\n",
    "y = dataset['Sleep Disorder']\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_columns = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "X[numerical_columns] = scaler.fit_transform(X[numerical_columns])\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check class balance\n",
    "print(\"Class distribution in training set:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "# Define models and hyperparameters\n",
    "models_and_params = {\n",
    "    \"LogisticRegression\": {\n",
    "        \"model\": LogisticRegression(max_iter=1000),\n",
    "        \"params\": {\"C\": [0.1, 1, 10, 100]}\n",
    "    },\n",
    "    \"RandomForestClassifier\": {\n",
    "        \"model\": RandomForestClassifier(),\n",
    "        \"params\": {\"n_estimators\": [50, 100, 200], \"max_depth\": [None, 10, 20, 30]}\n",
    "    },\n",
    "    \"SVC\": {\n",
    "        \"model\": SVC(),\n",
    "        \"params\": {\"C\": [0.1, 1, 10], \"kernel\": [\"linear\", \"rbf\"]}\n",
    "    },\n",
    "    \"DecisionTreeClassifier\": {\n",
    "        \"model\": DecisionTreeClassifier(),\n",
    "        \"params\": {\"max_depth\": [None, 10, 20, 30], \"min_samples_split\": [2, 5, 10]}\n",
    "    },\n",
    "    \"KNeighborsClassifier\": {\n",
    "        \"model\": KNeighborsClassifier(),\n",
    "        \"params\": {\"n_neighbors\": [3, 5, 7], \"weights\": [\"uniform\", \"distance\"]}\n",
    "    },\n",
    "    \"GradientBoostingClassifier\": {\n",
    "        \"model\": GradientBoostingClassifier(),\n",
    "        \"params\": {\"n_estimators\": [50, 100, 200], \"learning_rate\": [0.01, 0.1, 0.2]}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV for each model\n",
    "best_models = {}\n",
    "results = {}\n",
    "\n",
    "for model_name, config in models_and_params.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    grid_search = GridSearchCV(config[\"model\"], config[\"params\"], cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Save the best model and its accuracy\n",
    "    best_models[model_name] = grid_search.best_estimator_\n",
    "    y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{model_name} - Best Params: {grid_search.best_params_}\")\n",
    "    print(f\"{model_name} - Accuracy: {accuracy}\")\n",
    "    print(f\"{model_name} - Classification Report:\\n{classification_report(y_test, y_pred)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a6860c-3ff7-47bf-99a5-61f7c56e7736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the target column (disorder column)\n",
    "disorder_column = df['Disorder']  # replace 'Disorder' with your actual target column name\n",
    "\n",
    "# Checking for the percentage of missing values\n",
    "missing_percentage = disorder_column.isnull().mean() * 100\n",
    "print(f\"Percentage of missing values in Disorder column: {missing_percentage:.2f}%\")\n",
    "\n",
    "# Handle missing values\n",
    "# Option 1: Drop rows with missing target variable values\n",
    "df_cleaned = df.dropna(subset=['Disorder'])\n",
    "\n",
    "# Option 2: Fill missing values (if applicable, depending on the situation)\n",
    "# For example, fill with the most frequent disorder\n",
    "most_frequent_disorder = disorder_column.mode()[0]\n",
    "df_filled = df.fillna({'Disorder': most_frequent_disorder})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e8e7520-b3a9-494b-adc9-e90586e80445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in training set:\n",
      "Sleep Disorder\n",
      "2    0.588629\n",
      "1    0.207358\n",
      "0    0.204013\n",
      "Name: proportion, dtype: float64\n",
      "Class distribution after balancing:\n",
      "Sleep Disorder\n",
      "0    0.333333\n",
      "2    0.333333\n",
      "1    0.333333\n",
      "Name: proportion, dtype: float64\n",
      "Training LogisticRegression...\n",
      "LogisticRegression - Best Params: {'C': 1}\n",
      "LogisticRegression - Accuracy: 0.9066666666666666\n",
      "LogisticRegression - Classification zReport:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.82        16\n",
      "           1       0.92      0.75      0.83        16\n",
      "           2       0.95      0.98      0.97        43\n",
      "\n",
      "    accuracy                           0.91        75\n",
      "   macro avg       0.89      0.87      0.87        75\n",
      "weighted avg       0.91      0.91      0.91        75\n",
      "\n",
      "\n",
      "Training RandomForestClassifier...\n",
      "RandomForestClassifier - Best Params: {'max_depth': 10, 'n_estimators': 100}\n",
      "RandomForestClassifier - Accuracy: 0.88\n",
      "RandomForestClassifier - Classification zReport:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.81      0.76        16\n",
      "           1       0.85      0.69      0.76        16\n",
      "           2       0.95      0.98      0.97        43\n",
      "\n",
      "    accuracy                           0.88        75\n",
      "   macro avg       0.84      0.83      0.83        75\n",
      "weighted avg       0.88      0.88      0.88        75\n",
      "\n",
      "\n",
      "Training SVC...\n",
      "SVC - Best Params: {'C': 1, 'kernel': 'linear'}\n",
      "SVC - Accuracy: 0.8933333333333333\n",
      "SVC - Classification zReport:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.79        16\n",
      "           1       0.86      0.75      0.80        16\n",
      "           2       0.95      0.98      0.97        43\n",
      "\n",
      "    accuracy                           0.89        75\n",
      "   macro avg       0.86      0.85      0.85        75\n",
      "weighted avg       0.89      0.89      0.89        75\n",
      "\n",
      "\n",
      "Training DecisionTreeClassifier...\n",
      "DecisionTreeClassifier - Best Params: {'max_depth': 20, 'min_samples_split': 5}\n",
      "DecisionTreeClassifier - Accuracy: 0.8666666666666667\n",
      "DecisionTreeClassifier - Classification zReport:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.79        16\n",
      "           1       0.85      0.69      0.76        16\n",
      "           2       0.91      0.95      0.93        43\n",
      "\n",
      "    accuracy                           0.87        75\n",
      "   macro avg       0.84      0.82      0.83        75\n",
      "weighted avg       0.87      0.87      0.86        75\n",
      "\n",
      "\n",
      "Training KNeighborsClassifier...\n",
      "KNeighborsClassifier - Best Params: {'n_neighbors': 3, 'weights': 'uniform'}\n",
      "KNeighborsClassifier - Accuracy: 0.8666666666666667\n",
      "KNeighborsClassifier - Classification zReport:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.81      0.76        16\n",
      "           1       0.79      0.69      0.73        16\n",
      "           2       0.95      0.95      0.95        43\n",
      "\n",
      "    accuracy                           0.87        75\n",
      "   macro avg       0.82      0.82      0.82        75\n",
      "weighted avg       0.87      0.87      0.87        75\n",
      "\n",
      "\n",
      "Training GradientBoostingClassifier...\n",
      "GradientBoostingClassifier - Best Params: {'learning_rate': 0.2, 'n_estimators': 100}\n",
      "GradientBoostingClassifier - Accuracy: 0.9066666666666666\n",
      "GradientBoostingClassifier - Classification zReport:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81        16\n",
      "           1       0.87      0.81      0.84        16\n",
      "           2       0.95      0.98      0.97        43\n",
      "\n",
      "    accuracy                           0.91        75\n",
      "   macro avg       0.88      0.87      0.87        75\n",
      "weighted avg       0.91      0.91      0.91        75\n",
      "\n",
      "\n",
      "Best model saved as best_sleep_disorder_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pickle\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Sleep_health_and_lifestyle_dataset.csv'\n",
    "dataset = pd.read_csv(file_path)\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_columns = ['Gender', 'Occupation', 'BMI Category', 'Blood Pressure', 'Sleep Disorder']\n",
    "encoders = {col: LabelEncoder() for col in categorical_columns}\n",
    "for col in categorical_columns:\n",
    "    dataset[col] = encoders[col].fit_transform(dataset[col])\n",
    "\n",
    "# Separate features and target\n",
    "X = dataset.drop(columns=['Person ID', 'Sleep Disorder'])  # Drop ID and target column\n",
    "y = dataset['Sleep Disorder']\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_columns = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "X[numerical_columns] = scaler.fit_transform(X[numerical_columns])\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check class balance\n",
    "print(\"Class distribution in training set:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "# Apply SMOTE to balance the dataset\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check class distribution after balancing\n",
    "print(\"Class distribution after balancing:\")\n",
    "print(pd.Series(y_train_balanced).value_counts(normalize=True))\n",
    "\n",
    "# Define models and hyperparameters\n",
    "models_and_params = {\n",
    "    \"LogisticRegression\": {\n",
    "        \"model\": LogisticRegression(max_iter=1000),\n",
    "        \"params\": {\"C\": [0.1, 1, 10, 100]}\n",
    "    },\n",
    "    \"RandomForestClassifier\": {\n",
    "        \"model\": RandomForestClassifier(),\n",
    "        \"params\": {\"n_estimators\": [50, 100, 200], \"max_depth\": [None, 10, 20, 30]}\n",
    "    },\n",
    "    \"SVC\": {\n",
    "        \"model\": SVC(),\n",
    "        \"params\": {\"C\": [0.1, 1, 10], \"kernel\": [\"linear\", \"rbf\"]}\n",
    "    },\n",
    "    \"DecisionTreeClassifier\": {\n",
    "        \"model\": DecisionTreeClassifier(),\n",
    "        \"params\": {\"max_depth\": [None, 10, 20, 30], \"min_samples_split\": [2, 5, 10]}\n",
    "    },\n",
    "    \"KNeighborsClassifier\": {\n",
    "        \"model\": KNeighborsClassifier(),\n",
    "        \"params\": {\"n_neighbors\": [3, 5, 7], \"weights\": [\"uniform\", \"distance\"]}\n",
    "    },\n",
    "    \"GradientBoostingClassifier\": {\n",
    "        \"model\": GradientBoostingClassifier(),\n",
    "        \"params\": {\"n_estimators\": [50, 100, 200], \"learning_rate\": [0.01, 0.1, 0.2]}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV for each model\n",
    "best_models = {}\n",
    "results = {}\n",
    "\n",
    "for model_name, config in models_and_params.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    grid_search = GridSearchCV(config[\"model\"], config[\"params\"], cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "    grid_search.fit(X_train_balanced, y_train_balanced)\n",
    "    \n",
    "    # Save the best model and its accuracy\n",
    "    best_models[model_name] = grid_search.best_estimator_\n",
    "    y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{model_name} - Best Params: {grid_search.best_params_}\")\n",
    "    print(f\"{model_name} - Accuracy: {accuracy}\")\n",
    "    print(f\"{model_name} - Classification zReport:\\n{classification_report(y_test, y_pred)}\\n\")\n",
    "\n",
    "# Save the best-performing model (Logistic Regression example)\n",
    "best_model = LogisticRegression(C=10, max_iter=1000)\n",
    "best_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Save the model as a .pkl file\n",
    "model_filename = \"best_sleep_disorder_model.pkl\"\n",
    "with open(model_filename, \"wb\") as file:\n",
    "    pickle.dump(best_model, file)\n",
    "\n",
    "print(f\"Best model saved as {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2aef96c-3e65-496c-9e9b-c4ea8531d3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_columns:\n",
    "    with open(f\"{col}_encoder.pkl\", \"wb\") as file:\n",
    "        pickle.dump(encoders[col], file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c12a35c-f94c-4708-8f28-8fc6ecf1dd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"scaler.pkl\", \"wb\") as file:\n",
    "    pickle.dump(scaler, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af3e2903-6404-498d-b08e-16470f1a287d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoders saved to encoders.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "\n",
    "# Load your dataset\n",
    "file_path = 'Sleep_health_and_lifestyle_dataset.csv'\n",
    "dataset = pd.read_csv(file_path)\n",
    "\n",
    "# Define categorical columns\n",
    "categorical_columns = ['Gender', 'Occupation', 'BMI Category', 'Blood Pressure', 'Sleep Disorder']\n",
    "\n",
    "# Create LabelEncoders and encode the dataset\n",
    "encoders = {col: LabelEncoder() for col in categorical_columns}\n",
    "for col in categorical_columns:\n",
    "    dataset[col] = encoders[col].fit_transform(dataset[col])\n",
    "\n",
    "# Save the encoders as a pickle file\n",
    "with open('encoders.pkl', 'wb') as file:\n",
    "    pickle.dump(encoders, file)\n",
    "\n",
    "print(\"Encoders saved to encoders.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e18c38e-cf28-4606-ad2d-ab44a49e1d05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
